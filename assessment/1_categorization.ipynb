{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: right; height: 80px;\" src=\"../_static/ENGAGE.png\">\n",
    "\n",
    "# 1. Scenario categorization\n",
    "\n",
    "<a href=\"https://github.com/iiasa/ENGAGE-netzero-analysis/blob/main/LICENSE\">\n",
    "<img style=\"float: left; height: 30px; padding: 5px; margin-top: 8px; \" src=\"https://img.shields.io/github/license/iiasa/ENGAGE-netzero-analysis\">\n",
    "</a>\n",
    "\n",
    "Licensed under the [MIT License](https://github.com/iiasa/ENGAGE-netzero-analysis/blob/main/LICENSE).\n",
    "\n",
    "This notebook is part of a repository to generate figures and analysis for the manuscript\n",
    "\n",
    "> Keywan Riahi, Christoph Bertram, Daniel Huppmann, et al. <br />\n",
    "> Cost and attainability of meeting stringent climate targets without overshoot <br />\n",
    "> **Nature Climate Change**, 2021 <br />\n",
    "> doi: [10.1038/s41558-021-01215-2](https://doi.org/10.1038/s41558-021-01215-2)\n",
    "\n",
    "The scenario data used in this analysis should be cited as\n",
    "\n",
    "> ENGAGE Global Scenarios (Version 2.0) <br />\n",
    "> doi: [10.5281/zenodo.5553976](https://doi.org/10.5281/zenodo.5553976)\n",
    "\n",
    "The data can be accessed and downloaded via the **ENGAGE Scenario Explorer** at [https://data.ece.iiasa.ac.at/engage](https://data.ece.iiasa.ac.at/engage).<br />\n",
    "*Please refer to the [license](https://data.ece.iiasa.ac.at/engage/#/license)\n",
    "of the scenario ensemble before redistributing this data or adapted material.*\n",
    "\n",
    "The source code of this notebook is available on GitHub\n",
    "at [https://github.com/iiasa/ENGAGE-netzero-analysis](https://github.com/iiasa/ENGAGE-netzero-analysis).<br />\n",
    "A rendered version can be seen at [https://data.ece.iiasa.ac.at/engage-netzero-analysis](https://data.ece.iiasa.ac.at/engage-netzero-analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pyam\n",
    "from pyam import IamDataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the scenario snapshot used for this analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = Path(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = IamDataFrame(data_folder / \"ENGAGE_snapshot_selected.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set categories and meta indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set scenario type (budget logic) and family (NPi vs. INDCi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_type = {\n",
    "    \"0\": \"peak_budget\",\n",
    "    \"f\": \"full_century_budget\",\n",
    "    \"p\": \"sensitivity\",\n",
    "}\n",
    "\n",
    "def assign_type(i):\n",
    "    if i in [\"EN_NPi2100\", \"EN_INDCi2100\", \"EN_NoPolicy\"]:\n",
    "        return \"reference\"\n",
    "    return scenario_type[i[-1]]\n",
    "\n",
    "df.set_meta([assign_type(s) for m, s in df.index], \"budget_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_family = {\n",
    "    \"NoPolicy\": \"baseline\",\n",
    "    \"NPi\": \"NPi\",\n",
    "    \"INDCi\": \"INDCi\"\n",
    "}\n",
    "\n",
    "def assign_family(i):\n",
    "    for key, value in scenario_family.items():\n",
    "        if i.startswith(f\"EN_{key}\"):\n",
    "            return value\n",
    "\n",
    "df.set_meta([assign_family(s) for m, s in df.index], \"scenario_family\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closure of CO2 emissions regional & sectoral hierarchy\n",
    "\n",
    "Compute \"Emissions|CO2|Other\" and \"Emissions|CO2|Energy|Demand|Other\" explicitly to ensure consistent data.\n",
    "\n",
    "**Note**: The unit of CO2 Emissions \"Mt CO2/yr\" cannot be directly handled by the [**iam-units**](https://github.com/iamconsortium/units) package,\n",
    "which supports unit-handling of the algebraic operations in the **pyam** package.\n",
    "Therefore, the following cells override the automated unit-handling and set the units explicitly\n",
    "using the keyword argument `ignore_units=\"Mt CO2/yr\"`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co2 = \"Emissions|CO2\"\n",
    "\n",
    "df.subtract(\n",
    "    co2,\n",
    "    [f\"{co2}|{cat}\" for cat in [\"AFOLU\", \"Energy|Demand\", \"Energy|Supply\", \"Industrial Processes\"]],\n",
    "    f\"{co2}|Other\",\n",
    "    append=True,\n",
    "    ignore_units=\"Mt CO2/yr\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co2_demand = \"Emissions|CO2|Energy|Demand\"\n",
    "\n",
    "df.subtract(\n",
    "    co2_demand,\n",
    "    [f\"{co2_demand}|{cat}\" for cat in [\"Industry\", \"Transportation\", \"Residential and Commercial\"]],\n",
    "    f\"{co2_demand}|Other\",\n",
    "    append=True,\n",
    "    ignore_units=\"Mt CO2/yr\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r5_regions = df.region\n",
    "r5_regions.remove(\"World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_co2 = df.filter(variable=co2)\n",
    "df_co2_other_region = df_co2.subtract(\"World\", r5_regions, \"Other (R5)\", axis=\"region\", ignore_units=\"Mt CO2/yr\")\n",
    "df.append(df_co2_other_region, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute cumulative CO2 emissions and year of netzero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co2 = (\n",
    "    df.filter(region=\"World\", variable=\"Emissions|CO2\")\n",
    "    .convert_unit(\"Mt CO2/yr\", \"Gt CO2/yr\")\n",
    "    .timeseries()\n",
    ")\n",
    "\n",
    "def calculate_cumulative(last_year):\n",
    "    return co2.apply(pyam.cumulative, raw=False, axis=1,\n",
    "                     first_year=2020, last_year=last_year)\n",
    "\n",
    "df.set_meta(calculate_cumulative(2100), \"cumulative_emissions_2100\")\n",
    "df.set_meta(calculate_cumulative(2050), \"cumulative_emissions_2050\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _cross_threshold(x):\n",
    "    y = pyam.cross_threshold(x, threshold=0.1)\n",
    "    # set threshold slightly above 0 to catch convergence to 0\n",
    "    return y[0] if len(y) else np.nan\n",
    "\n",
    "def calculate_netzero(_df):\n",
    "    return _df.apply(_cross_threshold, raw=False, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_meta(calculate_netzero(co2), \"netzero|CO2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine peak and end-of-century temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_warming = \"AR5 climate diagnostics|Temperature|Global Mean|MAGICC6|MED\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean_temperature = df.filter(variable=median_warming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean_temperature.set_meta_from_data(\"median warming at peak\", np.max)\n",
    "df_mean_temperature.set_meta_from_data(\"median warming in 2100\", year=2100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_decline = (\n",
    "    df_mean_temperature.meta[\"median warming at peak\"]\n",
    "    - df_mean_temperature.meta[\"median warming in 2100\"]\n",
    ")\n",
    "\n",
    "df_mean_temperature.set_meta(peak_decline, \"median warming peak-and-decline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_of_peak_warming(x):\n",
    "    return int(x[x == x.max()].index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean_temperature.set_meta(\n",
    "    df_mean_temperature.timeseries().apply(year_of_peak_warming, raw=False, axis=1),\n",
    "    \"year of peak warming\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge new meta columns back to IamDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_mean_temperature.meta.columns:\n",
    "    if i not in df.meta.columns:\n",
    "        df.set_meta(df_mean_temperature.meta[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperature categorization using probabilistic MAGICC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warming_exceedance_prob(x):\n",
    "    return \"AR5 climate diagnostics|Temperature|Exceedance Probability|{} degC|MAGICC6\".format(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_meta(meta=\"uncategorized\", name=\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorization with several criteria hinging on the same variable need to be implemented iteratively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyam.categorize(df, exclude=False, category=\"uncategorized\",\n",
    "                value=\"low overshoot\", name=\"category\",\n",
    "                criteria={warming_exceedance_prob(1.5): {\"up\": 0.66}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyam.categorize(df, exclude=False, category=\"low overshoot\",\n",
    "                value=\"1.5C (with low overshoot)\", name=\"category\",\n",
    "                criteria={warming_exceedance_prob(1.5): {\"up\": 0.50, \"year\": 2100}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset the remaining `low_overshoot` scenarios to `uncategorized`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_meta(meta=\"uncategorized\", name=\"category\", index=df.filter(category=\"low overshoot\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remaining below 2°C with 66% probability means that the exceedance probability has to be (at most) 34%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyam.categorize(df, exclude=False, category=\"uncategorized\",\n",
    "                value=\"2C\", name=\"category\",\n",
    "                criteria={warming_exceedance_prob(2.0): {\"up\": 0.34}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyam.categorize(df, exclude=False, category=\"uncategorized\",\n",
    "                value=\"2.5C\", name=\"category\",\n",
    "                criteria={warming_exceedance_prob(2.5): {\"up\": 0.34}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All remaining `uncategorized` scenarios exceed the 2°C threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_meta(meta=\">2.5C\", name=\"category\", index=df.filter(category=\"uncategorized\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature categorization by corresponding peak-budget scenario\n",
    "\n",
    "The meta indicator **category_peak** maps the assigned category of a peak-budget scenario\n",
    "to the corresponding full-century budget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_peak = df.filter(budget_type=\"peak_budget\")\n",
    "df_fullcentury = df.filter(budget_type=\"full_century_budget\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_meta(meta=df_peak[\"category\"], name=\"category_peak\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_mapping = dict([(s, f\"{s}f\") for s in df_peak.scenario])\n",
    "full_century_index = pyam.index.replace_index_values(df_peak, \"scenario\", scenario_mapping)\n",
    "\n",
    "peak_category = pd.Series(data=df_peak[\"category\"].values, index=full_century_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_meta(\n",
    "    meta=peak_category[peak_category.index.intersection(df_fullcentury.index)],\n",
    "    name=\"category_peak\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to file\n",
    "\n",
    "Save full scenario ensemble data as well as subsets for particular figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(data_folder / \"ENGAGE_processed_snapshot.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exclude sensitivity scenarios for use in analysis and figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis = df.filter(scenario=\"*p\", keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis.filter(\n",
    "    variable=[\"Emissions|CO2\", \"Emissions|Kyoto Gases\"],\n",
    "    region=\"World\"\n",
    ").to_excel(data_folder / \"ENGAGE_fig1.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis.filter(\n",
    "    variable=[\"GDP|*\", \"Price|Carbon\"],\n",
    "    region=\"World\"\n",
    ").to_excel(data_folder / \"ENGAGE_fig2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis.filter(\n",
    "    variable=\"Emissions|CO2*\",\n",
    ").to_excel(data_folder / \"ENGAGE_fig3.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export sensitivity scenarios as own file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(\n",
    "    model=\"MESSAGEix-GLOBIOM 1.1\",\n",
    "    scenario=[f\"EN_NPi2020_{b}*\" for b in [1000, 600]],\n",
    ").to_excel(data_folder / \"ENGAGE_MESSAGE_sensitivity_runs.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
